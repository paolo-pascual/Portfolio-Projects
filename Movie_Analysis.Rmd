---
title: "Movie Analysis"
output: html_notebook
---

```{r}
load("Movie.Rdata")
loadhistory("Movie.Rhistory")
```

```{r}
#save workspace
save.image("Movie.Rdata")
savehistory("Movie.Rhistory")
```

```{r}
# loading needed libraries
library(tidymodels)
library(tidyverse)
library(Hmisc)
library(corrplot)
```

## Reading The Data

```{r}
movie <- read_csv("movies.csv", 
                 col_names = TRUE,
                 col_select = c("gross"
                                ,"budget"
                                ,"score"
                                ,"genre"
                                ,"country")
                )

```

```{r}
head(movie, 10)
```
## Preparing Categorical Data
Converting genre and country to factors with sensible number of levels

```{r}
# We first observe the distribution

movie %>% count(genre, sort = T) %>% head(5)
movie %>% count (country, sort = T) %>% head(5)
```
```{r}
# reducing the number of levels for genre and country and subsequently making them factors
movie1 <- 
movie %>% mutate(genre = ifelse(genre %in% c("Comedy", "Action", "Drama"),genre, "Others")
                 %>% as.factor(),
                 country = ifelse(country != "United States","Others", country)
                 %>% as.factor())
```

```{r}
# rechecking if the conversion is successful
movie1 %>% count(genre, sort = T) %>% head(5)
movie1 %>% count (country, sort = T) %>% head(5)
```

```{r}
head(movie1, 10)
```


## Cleaning Up Columns

```{r}
movie1 %>% map(~sum(is.na(.)))
```
Since there are several missing data, I decided to do listwise deletion. I chose this method because I believe that the dataset is large enough even though some are deleted.

```{r}
movie1 <- movie1 %>% drop_na(budget, gross, country)
```

```{r}
movie1 %>% map(~sum(is.na(.)))
```
## Exploratory Data Analysis

```{r}
# Splitting the data into training and testing sets

set.seed(1234)
movie_split <- initial_split(movie1, prop = 0.8)
movie_training <- training(movie_split)
movie_testing <- testing(movie_split)
```


```{r}
# Descriptive statistics
summary(movie_training)
```
```{r}
# Group by analysis for genre
movie_training %>% group_by(genre) %>%
           summarise(ave_gross = mean(gross),
                     ave_budget = mean(budget),
                     ave_score = mean(score))
```

```{r}
# Group by analysis for country
movie_training %>% group_by(country) %>%
           summarise(ave_gross = mean(gross),
                     ave_budget = mean(budget),
                     ave_score = mean(score))
```
```{r}
# Observing the distribution of the numerical data
par(mfrow=c(2,3))
hist(movie_training$gross)
hist(movie_training$budget)
hist(movie_training$score)
boxplot(movie_training$gross)
boxplot(movie_training$budget)
boxplot(movie_training$score)
```
We can see that gross and budget are both left-skewed while movie score resembles normality.

```{r}
# correlation matrix for numeric data
cormatrix <- 
movie_training %>% select("gross", "budget", "score") %>%
as.matrix() %>% rcorr()
```

```{r}
# Visualizing the correlation matrix using a correlogram
par(mfrow=c(1,2))
corrplot(cormatrix$r, method = "number")
corrplot(cormatrix$r, method = "pie")
```

## Linear Regression - Building Models

In this part, I built two models with gross as the response variable. These models explain how the chosen predicted variable influence the change in gross income. Subsequently, these two  models were subjected to test using measures, namely, root means square error and coefficient of determination to determine which performed better.

```{r}
lm_spec <- linear_reg() %>% 
  set_engine(engine = "lm")
lm_spec
```
### Model 1


```{r}
train_fit_1 <- lm_spec %>%
             fit(gross ~ budget + score + genre + country, data = movie_training)
train_fit_1
```

```{r}
train_results_1 <- train_fit_1 %>%
  predict(new_data = movie_training)  %>%
  mutate(truth = movie_training$gross)

head(train_results_1)
```

```{r}
rmse(train_results_1, truth = truth, estimate = .pred)
```
```{r}
rsq(train_results_1, truth = truth, estimate = .pred)
```

## Model 2

```{r}
train_fit_2 <- lm_spec %>%
             fit(gross ~ poly(budget + score, 2, raw = T), data = movie_training)
train_fit_2
```

```{r}
train_results_2 <- train_fit_2 %>%
  predict(new_data = movie_training)  %>%
  mutate(truth = movie_training$gross)

head(train_results_2)
```


```{r}
rmse(train_results_2, truth = truth, estimate = .pred)
```

```{r}
rsq(train_results_2, truth = truth, estimate = .pred)
```

## Linear Regression - Testing the Models

```{r}
test_results_1 <- train_fit_1 %>%
  predict(new_data = movie_testing) %>%
  mutate(truth = movie_testing$gross)

head(test_results_1)
```


```{r}
rmse(test_results_1, truth = truth, estimate = .pred)
```

```{r}
rsq(test_results_1, truth = truth, estimate = .pred)
```

```{r}
test_results_2 <- train_fit_2 %>%
  predict(new_data = movie_testing) %>%
  mutate(truth = movie_testing$gross)

head(test_results_2)
```


```{r}
rmse(test_results_2, truth = truth, estimate = .pred)
```

```{r}
rsq(test_results_2, truth = truth, estimate = .pred)
```

## Summary of the Models' Performance

```{r}
model_names <- c("Model_1", "Model_2")
train_error <- c("118778653", "120661512")
test_error <- c("131550641", "128633630")
train_rsq <- c("0.5717206", "0.5580349")
test_rsq <- c("0.6070186", "0.625084")
comparison <- data.frame(model_names, train_error, test_error, train_rsq, test_rsq)
comparison
```

The performances of the two models are very interesting.
Model 1 has a lower error and higher coefficient of determination compared with Model 2 in the TRAINING data set.
However, Model 2 has a lower error and higher coefficient of determination compared with Model 1 in the TESTING data set.

This implies that Model 1 has a higher variance than Model 2. That said, Model 2 is better with prediction for data other that the testing set.


















